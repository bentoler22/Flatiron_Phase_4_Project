{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras import models\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = 'chest_xray/train/'\n",
    "test_folder = 'chest_xray/test/'\n",
    "val_folder = 'chest_xray/val/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 624 images belonging to 2 classes.\n",
      "Found 16 images belonging to 2 classes.\n",
      "Found 5216 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# get all the data in the directory split/test (180 images), and reshape them\n",
    "test_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        test_folder, batch_size=624) \n",
    "\n",
    "# get all the data in the directory split/validation (200 images), and reshape them\n",
    "val_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        val_folder, batch_size=16)\n",
    "\n",
    "# get all the data in the directory split/train (542 images), and reshape them\n",
    "train_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        train_folder, batch_size=5216)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the data sets\n",
    "train_images, train_labels = next(train_generator)\n",
    "test_images, test_labels = next(test_generator)\n",
    "val_images, val_labels = next(val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 5216\n",
      "Number of testing samples: 624\n",
      "Number of validation samples: 16\n",
      "train_images shape: (5216, 256, 256, 3)\n",
      "train_labels shape: (5216, 2)\n",
      "test_images shape: (624, 256, 256, 3)\n",
      "test_labels shape: (624, 2)\n",
      "val_images shape: (16, 256, 256, 3)\n",
      "val_labels shape: (16, 2)\n"
     ]
    }
   ],
   "source": [
    "# Explore your dataset again\n",
    "m_train = train_images.shape[0]\n",
    "num_px = train_images.shape[1]\n",
    "m_test = test_images.shape[0]\n",
    "m_val = val_images.shape[0]\n",
    "\n",
    "print (\"Number of training samples: \" + str(m_train))\n",
    "print (\"Number of testing samples: \" + str(m_test))\n",
    "print (\"Number of validation samples: \" + str(m_val))\n",
    "print (\"train_images shape: \" + str(train_images.shape))\n",
    "print (\"train_labels shape: \" + str(train_labels.shape))\n",
    "print (\"test_images shape: \" + str(test_images.shape))\n",
    "print (\"test_labels shape: \" + str(test_labels.shape))\n",
    "print (\"val_images shape: \" + str(val_images.shape))\n",
    "print (\"val_labels shape: \" + str(val_labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5216, 196608)\n",
      "(624, 196608)\n",
      "(16, 196608)\n"
     ]
    }
   ],
   "source": [
    "train_img = train_images.reshape(train_images.shape[0], -1)\n",
    "test_img = test_images.reshape(test_images.shape[0], -1)\n",
    "val_img = val_images.reshape(val_images.shape[0], -1)\n",
    "\n",
    "print(train_img.shape)\n",
    "print(test_img.shape)\n",
    "print(val_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = np.reshape(train_labels[:,0], (5216,1))\n",
    "test_y = np.reshape(test_labels[:,0], (624,1))\n",
    "val_y = np.reshape(val_labels[:,0], (16,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(20, activation='relu', input_shape=(196608,))) # 2 hidden layers\n",
    "model.add(layers.Dense(7, activation='relu'))\n",
    "model.add(layers.Dense(5, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "163/163 [==============================] - 6s 35ms/step - loss: 0.5258 - accuracy: 0.7458 - val_loss: 0.6886 - val_accuracy: 0.6875\n",
      "Epoch 2/50\n",
      "163/163 [==============================] - 5s 29ms/step - loss: 0.3648 - accuracy: 0.8530 - val_loss: 0.7393 - val_accuracy: 0.6875\n",
      "Epoch 3/50\n",
      "163/163 [==============================] - 5s 28ms/step - loss: 0.3078 - accuracy: 0.8949 - val_loss: 0.8179 - val_accuracy: 0.6875\n",
      "Epoch 4/50\n",
      "163/163 [==============================] - 4s 27ms/step - loss: 0.2805 - accuracy: 0.9061 - val_loss: 1.0469 - val_accuracy: 0.6250\n",
      "Epoch 5/50\n",
      "163/163 [==============================] - 4s 27ms/step - loss: 0.2550 - accuracy: 0.9185 - val_loss: 0.4567 - val_accuracy: 0.8750\n",
      "Epoch 6/50\n",
      "163/163 [==============================] - 5s 28ms/step - loss: 0.2380 - accuracy: 0.9258 - val_loss: 0.5670 - val_accuracy: 0.7500\n",
      "Epoch 7/50\n",
      "163/163 [==============================] - 4s 26ms/step - loss: 0.2385 - accuracy: 0.9248 - val_loss: 0.6491 - val_accuracy: 0.7500\n",
      "Epoch 8/50\n",
      "163/163 [==============================] - 5s 28ms/step - loss: 0.2108 - accuracy: 0.9335 - val_loss: 0.4586 - val_accuracy: 0.8125\n",
      "Epoch 9/50\n",
      "163/163 [==============================] - 4s 27ms/step - loss: 0.2051 - accuracy: 0.9379 - val_loss: 0.3658 - val_accuracy: 0.9375\n",
      "Epoch 10/50\n",
      "163/163 [==============================] - 4s 25ms/step - loss: 0.1950 - accuracy: 0.9421 - val_loss: 1.0312 - val_accuracy: 0.6250\n",
      "Epoch 11/50\n",
      "163/163 [==============================] - 4s 27ms/step - loss: 0.1787 - accuracy: 0.9507 - val_loss: 0.4774 - val_accuracy: 0.7500\n",
      "Epoch 12/50\n",
      "163/163 [==============================] - 4s 27ms/step - loss: 0.1846 - accuracy: 0.9429 - val_loss: 0.7232 - val_accuracy: 0.7500\n",
      "Epoch 13/50\n",
      "163/163 [==============================] - 4s 24ms/step - loss: 0.1833 - accuracy: 0.9402 - val_loss: 0.3730 - val_accuracy: 0.9375\n",
      "Epoch 14/50\n",
      "163/163 [==============================] - 4s 23ms/step - loss: 0.1655 - accuracy: 0.9486 - val_loss: 0.2658 - val_accuracy: 0.9375\n",
      "Epoch 15/50\n",
      "163/163 [==============================] - 4s 24ms/step - loss: 0.1603 - accuracy: 0.9534 - val_loss: 0.2923 - val_accuracy: 0.9375\n",
      "Epoch 16/50\n",
      "163/163 [==============================] - 4s 24ms/step - loss: 0.1692 - accuracy: 0.9442 - val_loss: 0.9638 - val_accuracy: 0.6250\n",
      "Epoch 17/50\n",
      "163/163 [==============================] - 4s 24ms/step - loss: 0.1594 - accuracy: 0.9505 - val_loss: 0.2601 - val_accuracy: 0.9375\n",
      "Epoch 18/50\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.1485 - accuracy: 0.95 - 4s 24ms/step - loss: 0.1489 - accuracy: 0.9526 - val_loss: 0.3967 - val_accuracy: 0.8125\n",
      "Epoch 19/50\n",
      "163/163 [==============================] - 4s 24ms/step - loss: 0.1520 - accuracy: 0.9523 - val_loss: 0.3457 - val_accuracy: 0.9375\n",
      "Epoch 20/50\n",
      "163/163 [==============================] - 4s 24ms/step - loss: 0.1508 - accuracy: 0.9500 - val_loss: 0.2222 - val_accuracy: 0.9375\n",
      "Epoch 21/50\n",
      "163/163 [==============================] - 4s 24ms/step - loss: 0.1419 - accuracy: 0.9549 - val_loss: 0.2331 - val_accuracy: 0.9375\n",
      "Epoch 22/50\n",
      "163/163 [==============================] - 4s 25ms/step - loss: 0.1512 - accuracy: 0.9502 - val_loss: 0.3557 - val_accuracy: 0.8750\n",
      "Epoch 23/50\n",
      "163/163 [==============================] - 4s 25ms/step - loss: 0.1311 - accuracy: 0.9590 - val_loss: 0.2695 - val_accuracy: 0.9375\n",
      "Epoch 24/50\n",
      "163/163 [==============================] - 4s 25ms/step - loss: 0.1375 - accuracy: 0.9534 - val_loss: 0.2083 - val_accuracy: 0.9375\n",
      "Epoch 25/50\n",
      "163/163 [==============================] - 4s 28ms/step - loss: 0.1311 - accuracy: 0.9572 - val_loss: 0.2029 - val_accuracy: 0.9375\n",
      "Epoch 26/50\n",
      "163/163 [==============================] - 5s 28ms/step - loss: 0.1343 - accuracy: 0.9551 - val_loss: 0.4653 - val_accuracy: 0.8125\n",
      "Epoch 27/50\n",
      "163/163 [==============================] - 4s 24ms/step - loss: 0.1341 - accuracy: 0.9557 - val_loss: 0.5337 - val_accuracy: 0.8125\n",
      "Epoch 28/50\n",
      "163/163 [==============================] - 4s 24ms/step - loss: 0.1313 - accuracy: 0.9574 - val_loss: 0.6904 - val_accuracy: 0.6875\n",
      "Epoch 29/50\n",
      "163/163 [==============================] - 4s 24ms/step - loss: 0.1285 - accuracy: 0.9584 - val_loss: 0.2734 - val_accuracy: 0.9375\n",
      "Epoch 30/50\n",
      "163/163 [==============================] - 4s 23ms/step - loss: 0.1255 - accuracy: 0.9586 - val_loss: 0.9855 - val_accuracy: 0.6875\n",
      "Epoch 31/50\n",
      "163/163 [==============================] - 4s 23ms/step - loss: 0.1236 - accuracy: 0.9603 - val_loss: 0.3541 - val_accuracy: 0.9375\n",
      "Epoch 32/50\n",
      "163/163 [==============================] - 4s 25ms/step - loss: 0.1244 - accuracy: 0.9567 - val_loss: 0.2965 - val_accuracy: 0.9375\n",
      "Epoch 33/50\n",
      "163/163 [==============================] - 4s 25ms/step - loss: 0.1243 - accuracy: 0.9592 - val_loss: 0.4601 - val_accuracy: 0.8125\n",
      "Epoch 34/50\n",
      "163/163 [==============================] - 5s 28ms/step - loss: 0.1196 - accuracy: 0.9590 - val_loss: 0.4412 - val_accuracy: 0.8125\n",
      "Epoch 35/50\n",
      "163/163 [==============================] - 4s 27ms/step - loss: 0.1219 - accuracy: 0.9628 - val_loss: 0.2306 - val_accuracy: 0.9375\n",
      "Epoch 36/50\n",
      "163/163 [==============================] - 4s 24ms/step - loss: 0.1195 - accuracy: 0.9601 - val_loss: 0.1850 - val_accuracy: 0.9375\n",
      "Epoch 37/50\n",
      "163/163 [==============================] - 4s 27ms/step - loss: 0.1195 - accuracy: 0.9592 - val_loss: 0.3442 - val_accuracy: 0.9375\n",
      "Epoch 38/50\n",
      "163/163 [==============================] - 4s 27ms/step - loss: 0.1249 - accuracy: 0.9549 - val_loss: 0.4714 - val_accuracy: 0.8125\n",
      "Epoch 39/50\n",
      "163/163 [==============================] - 4s 24ms/step - loss: 0.1180 - accuracy: 0.9601 - val_loss: 0.1916 - val_accuracy: 0.9375\n",
      "Epoch 40/50\n",
      "163/163 [==============================] - 4s 25ms/step - loss: 0.1143 - accuracy: 0.9618 - val_loss: 0.2037 - val_accuracy: 0.9375\n",
      "Epoch 41/50\n",
      "163/163 [==============================] - 4s 27ms/step - loss: 0.1072 - accuracy: 0.9655 - val_loss: 0.3824 - val_accuracy: 0.8750\n",
      "Epoch 42/50\n",
      "163/163 [==============================] - 5s 28ms/step - loss: 0.1123 - accuracy: 0.9618 - val_loss: 0.7463 - val_accuracy: 0.6875\n",
      "Epoch 43/50\n",
      "163/163 [==============================] - 4s 26ms/step - loss: 0.1079 - accuracy: 0.9636 - val_loss: 0.4519 - val_accuracy: 0.8125\n",
      "Epoch 44/50\n",
      "163/163 [==============================] - 4s 24ms/step - loss: 0.1049 - accuracy: 0.9651 - val_loss: 0.3867 - val_accuracy: 0.8125\n",
      "Epoch 45/50\n",
      "163/163 [==============================] - 4s 27ms/step - loss: 0.1086 - accuracy: 0.9632 - val_loss: 0.2024 - val_accuracy: 0.9375\n",
      "Epoch 46/50\n",
      "163/163 [==============================] - 4s 27ms/step - loss: 0.1076 - accuracy: 0.9657 - val_loss: 0.2035 - val_accuracy: 0.9375\n",
      "Epoch 47/50\n",
      "163/163 [==============================] - 4s 27ms/step - loss: 0.1149 - accuracy: 0.9607 - val_loss: 0.2328 - val_accuracy: 0.9375\n",
      "Epoch 48/50\n",
      "163/163 [==============================] - 5s 28ms/step - loss: 0.1050 - accuracy: 0.9643 - val_loss: 0.4969 - val_accuracy: 0.8125\n",
      "Epoch 49/50\n",
      "163/163 [==============================] - 4s 27ms/step - loss: 0.1057 - accuracy: 0.9632 - val_loss: 0.2857 - val_accuracy: 0.9375\n",
      "Epoch 50/50\n",
      "163/163 [==============================] - 4s 26ms/step - loss: 0.1059 - accuracy: 0.9655 - val_loss: 0.3877 - val_accuracy: 0.8750\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_img,\n",
    "                    train_y,\n",
    "                    epochs=50,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(val_img, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - 2s 12ms/step - loss: 0.0881 - accuracy: 0.9720\n"
     ]
    }
   ],
   "source": [
    "results_train = model.evaluate(train_img, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3877 - accuracy: 0.8750\n"
     ]
    }
   ],
   "source": [
    "results_val = model.evaluate(val_img, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
